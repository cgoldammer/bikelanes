{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercantile, mapbox_vector_tile, requests, json\n",
    "from vt2geojson.tools import vt_bytes_to_geojson\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import shapely\n",
    "import numpy as np\n",
    "\n",
    "from mapboxgl.utils import *\n",
    "from mapboxgl.viz import *\n",
    "\n",
    "import functions\n",
    "import imp\n",
    "import ipyplot\n",
    "\n",
    "import geopandas as gpd\n",
    "from PIL import Image\n",
    "\n",
    "import shapely\n",
    "\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "df_streets = functions.get_streets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "points = functions.nyc_borough_coordinates_shapely\n",
    "\n",
    "borough = 'Queens'\n",
    "name_start = 'Northwest_Tip'\n",
    "name_end = 'Southeast_Corner'\n",
    "\n",
    "point_start = points[borough][name_start]\n",
    "point_end = points[borough][name_end]\n",
    "\n",
    "tiles = functions.get_tiles(point_start, point_end)\n",
    "print(\"Number of tiles: \", len(tiles))\n",
    "functions.save_tiles(tiles)\n",
    "print(\"Done saving tiles\")\n",
    "\n",
    "max_tiles = 200\n",
    "# Take random sample of this size from tiles\n",
    "i_sampled = np.random.choice(len(tiles), min(len(tiles), max_tiles), replace=False)\n",
    "tiles_sampled = [t for (i,t) in enumerate(tiles) if i in i_sampled]\n",
    "\n",
    "df_images = functions.load_images(tiles_sampled)\n",
    "print(\"Number of images: \", len(df_images))\n",
    "\n",
    "imp.reload(functions)\n",
    "\n",
    "ls = shapely.LineString([point_start, point_end])\n",
    "point_mid = gpd.GeoSeries([ls.interpolate(0.5, normalized=True)], crs=functions.crs_geo).to_crs(functions.crs).iloc[0]\n",
    "\n",
    "df_streets['dist_mid'] = df_streets.geometry.apply(lambda p: p.distance(point_mid))\n",
    "df_images['dist_mid'] = df_images.geometry.apply(lambda p: p.distance(point_mid))\n",
    "\n",
    "outline = functions.outlines[borough]\n",
    "def dist_to_outline(p):\n",
    "    return p.distance(outline)\n",
    "\n",
    "df_streets['dist_outline'] = df_streets.geometry.apply(dist_to_outline)\n",
    "df_images['dist_outline'] = df_images.geometry.apply(dist_to_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mid = 4000000\n",
    "dist_outline = 0\n",
    "\n",
    "ds_start = '2017-01-01'\n",
    "\n",
    "df_streets_small = (df_streets\n",
    "                    .query(f'dist_mid <= {dist_mid}')\n",
    "                    .query(f'dist_outline <= {dist_outline}')\n",
    "                    .copy())\n",
    "\n",
    "df_images_small = (df_images\n",
    "                   .query('ds >= @ds_start')\n",
    "                   .query('~ is_pano')\n",
    "                   .query('~ is_coded')\n",
    "                   .query(f'dist_mid <= {dist_mid}')\n",
    "                   .query(f'dist_outline <= {dist_outline}')\n",
    "                   .copy())\n",
    "\n",
    "imp.reload(functions)\n",
    "max_dist_meters = 200\n",
    "df_streets_points = functions.explode_points(df_streets_small, max_dist_meters=max_dist_meters)\n",
    "df_streets_points.set_geometry('point', inplace=True)\n",
    "df_streets_points = df_streets_points\n",
    "len(df_images_small), len(df_streets_small), len(df_streets_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df_streets.plot()\n",
    "df_images.sample(1000).plot(ax=base, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df_streets_small.plot()\n",
    "df_images_small.plot(ax=base, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "buffer_meters = 100\n",
    "merged = functions.merge_multiple(df_streets_points, df_images_small, buffer_meters)\n",
    "\n",
    "merged['dist_line'] = [ls.distance(p) for ls, p in zip(merged.line_string, merged.point_image)]\n",
    "merged['min_dist_line_by_num_point'] = merged.groupby('linesegment_str').dist_line.transform('min')\n",
    "\n",
    "renamer = {\n",
    "    'id': 'id_image',\n",
    "    'compass_angle': 'angle_image',\n",
    "    'line_angle': 'angle_street'\n",
    "    }\n",
    "\n",
    "df = merged.rename(columns=renamer).query('dist_line <= 200').groupby('num_point').head(5).reset_index()\n",
    "images_before_coding = df.id_image.nunique()\n",
    "\n",
    "cols_key = ['id_image', 'num_point', 'angle_image', 'angle_street', \n",
    "            'distance_raw', 'distance_meters', 'time', 'segmentid', 'point', 'point_image']\n",
    "\n",
    "images_before_coding, df.id_image.nunique(), len(df), df_streets_points.point.nunique(), df.point.nunique(), df.groupby('num_point').distance_meters.min().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images as follows:\n",
    "# Start with a random image from merged dataset\n",
    "# Create a list of good candidates\n",
    "# Drop if:\n",
    "# - close to a point in the coded dataset\n",
    "# - close to other candidates\n",
    "# - angle is wrong\n",
    "# Stop after N images\n",
    "\n",
    "df_to_code = pd.DataFrame()\n",
    "df_coded = pd.read_csv('data/bike_coding_sheet_download.csv')\n",
    "ids_useful = list(df_coded.query('useful==1').id.unique().astype(int))\n",
    "assert len(ids_useful) > 100\n",
    "df_useful = df_images[df_images.id.isin(ids_useful)]\n",
    "\n",
    "num_to_code = 600\n",
    "dist_useful_cutoff = 100\n",
    "dist_current_cutoff = 50\n",
    "LARGE_NUMBER = 100000\n",
    "\n",
    "removed_for_close_to_useful = 0\n",
    "removed_for_close_to_coded = 0\n",
    "\n",
    "num_scaler = 100\n",
    "\n",
    "df['image_diff'] = np.abs(df.angle_image - df.angle_street) % 360\n",
    "angle_cutoff = 30\n",
    "df_take = df.query('image_diff <= @angle_cutoff').copy()\n",
    "print(len(df), len(df_take))\n",
    "df.set_geometry('point_image', inplace=True)\n",
    "\n",
    "for i in range(num_to_code * num_scaler):\n",
    "    if i % 500 == 0:\n",
    "        # Print the df size and all removal numbers in a nice format\n",
    "        print(f\"i: {i:4d} | df size: {len(df_to_code):4d} | useful: {removed_for_close_to_useful:4d} | in current data: {removed_for_close_to_coded:4d}\")\n",
    "    if len(df_to_code) >= num_to_code:\n",
    "        print(f\"Went through {i} iterations\")\n",
    "        break\n",
    "\n",
    "    if df_to_code.shape[0] >= 1:\n",
    "        df_to_code.set_geometry('point_image', inplace=True)\n",
    "\n",
    "    row_to_code = df_take.sample(1).iloc[0]\n",
    "    \n",
    "\n",
    "    if len(df_useful) > 0:\n",
    "        dist_useful = df_useful.geometry.apply(lambda p: p.distance(row_to_code.point_image)).min()\n",
    "        if dist_useful < dist_useful_cutoff:\n",
    "            removed_for_close_to_useful += 1\n",
    "            continue\n",
    "\n",
    "    dist_coded = LARGE_NUMBER if len(df_to_code)==0 else df_to_code.geometry.apply(lambda p: p.distance(row_to_code.point_image)).min()\n",
    "    if dist_coded < dist_current_cutoff:\n",
    "        removed_for_close_to_coded += 1\n",
    "        continue\n",
    "\n",
    "    df_new = pd.DataFrame([row_to_code])\n",
    "    df_to_code = pd.concat([df_to_code, df_new])\n",
    "    df_to_code = gpd.GeoDataFrame(df_to_code)\n",
    "\n",
    "len(df), len(df_to_code), df_to_code.id_image.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_coded), df_coded.useful.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1819"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pd.read_csv('data/bike_coding_sheet_download.csv')\n",
    "len(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_to_code), df_to_code.id_image.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "\n",
    "num_max = 600\n",
    "\n",
    "with open('/Users/cg/temp2/mapillary_token', 'r') as f:\n",
    "    token = f.read().strip()\n",
    "    functions.access_token_mapillary = token\n",
    "\n",
    "num_saved = 0\n",
    "for i, (_, feature) in enumerate(df_to_code.iterrows()):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"{i:3d}\")\n",
    "    # Stop the iteration after num_max\n",
    "    if i >= num_max:\n",
    "        break\n",
    "\n",
    "    image_id = feature['id_image']\n",
    "    \n",
    "    sequence_id = feature['sequence_id']\n",
    "    i, _ = functions.download_and_save_image(sequence_id, image_id)\n",
    "    num_saved += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [int(f.split('____')[1].split('.')[0]) for f in os.listdir('images') if '____' in f]\n",
    "df_to_code_images = df_to_code.loc[df_to_code.id_image.isin(ids), ].copy()\n",
    "df_to_code_images['num'] = range(len(df_to_code_images))\n",
    "num_saved, num_saved, len(ids), len(df_to_code), len(df_to_code_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "file_ids = '/Users/cg/temp2/ids_good.md' \n",
    "# Read the file into a list\n",
    "with open(file_ids, 'r') as f:\n",
    "    nums_good = f.read().replace(' ', '\\n').split('\\n')\n",
    "nums_good = [int(i) for i in nums_good if i != '']\n",
    "print(len(nums_good))\n",
    "\n",
    "df_to_code_images['is_good'] = df_to_code_images.num.isin(nums_good)\n",
    "df_to_code_images.query('is_good')[functions.cols_export_code].to_csv('data/to_code_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "\n",
    "filter_good = True\n",
    "filter_string = 'num < 10000' if not filter_good else 'is_good'\n",
    "scaler = 6 if filter_good else 12\n",
    "img_width = 400 if filter_good else 200\n",
    "num_im = 600\n",
    "\n",
    "ims = []\n",
    "for (_, r) in df_to_code_images.query(filter_string).iterrows():\n",
    "    try:\n",
    "        im = functions.get_image(r.sequence_id, r.id_image)\n",
    "        (x, y) = im.size\n",
    "        if x >= y:\n",
    "            im.thumbnail((x/scaler, y/scaler))\n",
    "            ims.append((im, r))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "images, rows = zip(*ims)\n",
    "def get_label(r):\n",
    "    facilit = f'FT: {r.ft} | TF: {r.tf}'\n",
    "    other = f'Im: {r.num:03d} | Time: {r.ds}'\n",
    "    return other + facilit\n",
    "\n",
    "labels=[get_label(r) for r in rows]\n",
    "ids_reviewed = df_to_code_images.id_image.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded = functions.get_df_coded()\n",
    "\n",
    "ids_spread = list(df_coded.query('~ useful').id.unique())\n",
    "ids_spread\n",
    "\n",
    "with open('data/ids_reviewed.txt', 'a') as f:\n",
    "    for i in ids_spread:\n",
    "        f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ids_reviewed.txt', 'r') as f:\n",
    "    ids_reviewed = f.read().split('\\n')\n",
    "len(set(ids_reviewed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot.plot_images(images, labels=labels, img_width=img_width, max_images=num_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_useful_raw = functions.load_all_images(ids_useful)\n",
    "folder_im = 'content/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_export[[c + '_int' for c in cols_lanes]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(functions)\n",
    "print(len(df_coded), len(df_coded.query('useful')))\n",
    "\n",
    "images_useful = images_useful_raw.copy()\n",
    "\n",
    "rescale_factor = 5\n",
    "do_copy = False\n",
    "overwrite = True\n",
    "\n",
    "# Get the useful images as files. The file name is provided by get_save_location\n",
    "# Then copy them to the folder content/images\n",
    "if do_copy:\n",
    "    for (i,row) in images_useful.iterrows():\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i:4d}\")\n",
    "        filename_current = functions.get_save_location(row.sequence_id, row.id)\n",
    "\n",
    "        # Remove the folder from the filename\n",
    "        filename_end = filename_current.split('/')[-1]\n",
    "        filename_new = f'images/smaller/{filename_end}'\n",
    "        # only run if filename_new doesn't yet exist\n",
    "        if os.path.exists(filename_new) and not overwrite:\n",
    "            continue\n",
    "\n",
    "        # Load the image and rescale it down by the rescale_factor\n",
    "        im = Image.open(filename_current)\n",
    "        (x, y) = im.size\n",
    "        im.thumbnail((x/rescale_factor, y/rescale_factor))\n",
    "\n",
    "        # Then savea s filename_new\n",
    "        im.save(filename_new)\n",
    "\n",
    "images_useful['location'] = images_useful.apply(lambda row: functions.get_save_location(row.sequence_id, row.id, folder_im), axis=1)\n",
    "\n",
    "def get_s3_location(location):\n",
    "    s3_folder = 'https://bikelanepictures.s3.amazonaws.com/'\n",
    "    # Extract the last part of the filename and add it\n",
    "    # to the s3 folder\n",
    "    filename = location.split('/')[-1]\n",
    "    return s3_folder + filename\n",
    "images_useful['s3_location'] = images_useful.location.apply(get_s3_location)\n",
    "\n",
    "\n",
    "images_useful['x'] = images_useful.geometry.to_crs(functions.crs_geo).apply(lambda p: p.x)\n",
    "images_useful['y'] = images_useful.geometry.to_crs(functions.crs_geo).apply(lambda p: p.y)\n",
    "images_useful['point_google'] = images_useful.geometry.to_crs(functions.crs_geo).apply(functions.point_google)\n",
    "\n",
    "val_protected = 'Protected Path'\n",
    "val_standard = 'Standard'\n",
    "val_sharrow = 'Sharrows'\n",
    "\n",
    "cols_export = ['s3_location', 'id', 'x', 'y', 'compass_angle', 'ds', 'point_google',\n",
    "               'is_protected', 'is_standard'] + obstructions + ['obstruct_car', 'lane_max']\n",
    "\n",
    "im_export = images_useful.merge(df_coded.query('useful').groupby('id').first().reset_index(), on='id', how='left')\n",
    "\n",
    "len(ids_useful), len(images_useful), len(im_export)\n",
    "\n",
    "\n",
    "im_export['obstruct_car'] = im_export.cars_standing | im_export.cars_moving\n",
    "im_export['is_protected'] = (im_export.tf_facilit == val_protected) | (im_export.ft_facilit == val_protected)\n",
    "im_export['is_standard'] = (im_export.tf_facilit == val_standard) | (im_export.ft_facilit == val_standard)\n",
    "im_export['is_sharrow'] = (im_export.tf_facilit == val_sharrow) | (im_export.ft_facilit == val_sharrow)\n",
    "\n",
    "im_export['is_protected_image'] = im_export.bike_lane & im_export[cols_protected].apply(max, axis=1)\n",
    "im_export['agrees_protected'] = im_export.is_protected & im_export.is_protected_image\n",
    "im_export['agrees_standard'] = im_export.is_standard & (~im_export.is_protected_image) & im_export.bike_lane\n",
    "im_export['agrees'] = im_export.agrees_protected | im_export.agrees_standard\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "im_export[cols_export].to_json('./docs/images.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp images/smaller s3://bikelanepictures --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protected\n",
    "\n",
    "Hypothesis: White lines count as \"protected\" in NYC official map. Let's confirm against more recent images from google street view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_validate = im_export.query('is_protected').query('white_separation == 1').query('plastic_stoppers == 0')\n",
    "rows = im_validate.head(12)\n",
    "locations = list(rows.location.head(12))\n",
    "print(create_markdown_table(locations))\n",
    "\n",
    "for i, (_, row) in enumerate(rows.iterrows()):\n",
    "    print(f'[{i}] / [{row.id}]: {row.point_google}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: has been improved since image, but not fully protected\n",
    "1: Correct: There are some plastic stoppers, but very intermittent\n",
    "3: Coded fine (should add the parking)\n",
    "3: Correct (as of Jul 2022)\n",
    "8: Correct (there is parking protection behind, but interrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a github markdown table with 4 columns\n",
    "# that display the images in the location in a grid\n",
    "# The markdown is returned from the function\n",
    "\n",
    "\n",
    "im_export['location_string'] = im_export.location.apply(get_s3_location)\n",
    "\n",
    "def markdown_table(location_strings, cols=4):\n",
    "    # Return a markdown table of images that are stored in the locations\n",
    "    # The table has cols columns\n",
    "    # The markdown is returned from the function\n",
    "    # Include the table header\n",
    "    md = '|'\n",
    "    for i in range(cols):\n",
    "        md += ' |'\n",
    "    md += '\\n|'\n",
    "    for i in range(cols):\n",
    "        md += '---|'\n",
    "    md += '\\n'\n",
    "    # Add the rows\n",
    "    for i in range(0, len(location_strings), cols):\n",
    "        md += '|'\n",
    "        for j in range(cols):\n",
    "            if i + j >= len(location_strings):\n",
    "                break\n",
    "            md += f'![]({location_strings[i+j]}) |'\n",
    "        md += '\\n'\n",
    "    return md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protected through parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = 12\n",
    "locations = list(im_export.query('is_protected').query('through_parking').sample(val_sample).location_string)\n",
    "print(markdown_table(locations))\n",
    "\n",
    "### Images: protectedparking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images: \"Protected\" without parking\n",
    "val_sample = 12\n",
    "locations = list(im_export.query('is_protected_image').query('~through_parking').location_string.sample(val_sample))\n",
    "print(markdown_table(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Images: Sharrows\n",
    "\n",
    "val_sample = 12\n",
    "locations = list(im_export.query('sharrow').sample(val_sample).location_string)\n",
    "print(markdown_table(locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean obstruction for each obstruction outcome by these split vars:\n",
    "split_vars = ['through_parking', 'white_separation', 'neither']\n",
    "# Store this in a dictionary corresponding to the two levels\n",
    "# of the split vars\n",
    "d = {}\n",
    "# Loop over the split var\n",
    "for split_var in split_vars:\n",
    "        df_var = im_export.query(f'{split_var}')\n",
    "        # Calculate the mean obstruction and the observation count by obstruction type\n",
    "        res = {}\n",
    "        for obstruction in obstructions:\n",
    "            vals = df_var[obstruction]\n",
    "            res[obstruction] = vals.sum(), vals.count()\n",
    "        d[split_var] = res\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# Take the ratio of each tuple from each cell\n",
    "df_ratio = df.applymap(lambda t: t[0]/t[1])\n",
    "df_ratio * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (df_streets\n",
    "          .groupby(['borough', 'lane_max'])\n",
    "          .length_miles.sum()\n",
    "          .unstack(1)\n",
    "          .astype(int)[functions.lanes_dict.values()])\n",
    "print(df_agg.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist_meters = 200\n",
    "obs = df_coded.query('useful').__len__()\n",
    "kms = int(df_streets.length_km.sum())\n",
    "full_coverage = kms * 1000 / max_dist_meters\n",
    "\n",
    "obs, kms, full_coverage, int(obs/full_coverage*100)\n",
    "\n",
    "# Summarize this in a dictionary\n",
    "d = {}\n",
    "d['useful'] = obs\n",
    "d['not_useful'] = len(set(ids_reviewed))\n",
    "d['total_reviewed'] = d['useful'] + d['not_useful']\n",
    "d['kilometers'] = kms\n",
    "d['miles'] = int(kms * 0.621371)\n",
    "d['meters_per_image'] = max_dist_meters\n",
    "d['images_full_coverage'] = int(full_coverage)\n",
    "d['percent_coverage'] = int(obs/full_coverage*100)\n",
    "summary = pd.Series(d)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
